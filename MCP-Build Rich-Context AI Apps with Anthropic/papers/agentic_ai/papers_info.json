{
  "2502.18359v1": {
    "title": "Responsible AI Agents",
    "authors": [
      "Deven R. Desai",
      "Mark O. Riedl"
    ],
    "summary": "Thanks to advances in large language models, a new type of software agent,\nthe artificial intelligence (AI) agent, has entered the marketplace. Companies\nsuch as OpenAI, Google, Microsoft, and Salesforce promise their AI Agents will\ngo from generating passive text to executing tasks. Instead of a travel\nitinerary, an AI Agent would book all aspects of your trip. Instead of\ngenerating text or images for social media post, an AI Agent would post the\ncontent across a host of social media outlets. The potential power of AI Agents\nhas fueled legal scholars' fears that AI Agents will enable rogue commerce,\nhuman manipulation, rampant defamation, and intellectual property harms. These\nscholars are calling for regulation before AI Agents cause havoc.\n  This Article addresses the concerns around AI Agents head on. It shows that\ncore aspects of how one piece of software interacts with another creates ways\nto discipline AI Agents so that rogue, undesired actions are unlikely, perhaps\nmore so than rules designed to govern human agents. It also develops a way to\nleverage the computer-science approach to value-alignment to improve a user's\nability to take action to prevent or correct AI Agent operations. That approach\noffers and added benefit of helping AI Agents align with norms around user-AI\nAgent interactions. These practices will enable desired economic outcomes and\nmitigate perceived risks. The Article also argues that no matter how much AI\nAgents seem like human agents, they need not, and should not, be given legal\npersonhood status. In short, humans are responsible for AI Agents' actions, and\nthis Article provides a guide for how humans can build and maintain responsible\nAI Agents.",
    "pdf_url": "http://arxiv.org/pdf/2502.18359v1",
    "published": "2025-02-25"
  },
  "2505.10468v3": {
    "title": "AI Agents vs. Agentic AI: A Conceptual Taxonomy, Applications and Challenges",
    "authors": [
      "Ranjan Sapkota",
      "Konstantinos I. Roumeliotis",
      "Manoj Karkee"
    ],
    "summary": "This study critically distinguishes between AI Agents and Agentic AI,\noffering a structured conceptual taxonomy, application mapping, and challenge\nanalysis to clarify their divergent design philosophies and capabilities. We\nbegin by outlining the search strategy and foundational definitions,\ncharacterizing AI Agents as modular systems driven by Large Language Models\n(LLMs) and Large Image Models (LIMs) for narrow, task-specific automation.\nGenerative AI is positioned as a precursor, with AI Agents advancing through\ntool integration, prompt engineering, and reasoning enhancements. In contrast,\nAgentic AI systems represent a paradigmatic shift marked by multi-agent\ncollaboration, dynamic task decomposition, persistent memory, and orchestrated\nautonomy. Through a sequential evaluation of architectural evolution,\noperational mechanisms, interaction styles, and autonomy levels, we present a\ncomparative analysis across both paradigms. Application domains such as\ncustomer support, scheduling, and data summarization are contrasted with\nAgentic AI deployments in research automation, robotic coordination, and\nmedical decision support. We further examine unique challenges in each paradigm\nincluding hallucination, brittleness, emergent behavior, and coordination\nfailure and propose targeted solutions such as ReAct loops, RAG, orchestration\nlayers, and causal modeling. This work aims to provide a definitive roadmap for\ndeveloping robust, scalable, and explainable AI agent and Agentic AI-driven\nsystems. >AI Agents, Agent-driven, Vision-Language-Models, Agentic AI Decision\nSupport System, Agentic-AI Applications",
    "pdf_url": "http://arxiv.org/pdf/2505.10468v3",
    "published": "2025-05-15"
  },
  "2403.15137v1": {
    "title": "CACA Agent: Capability Collaboration based AI Agent",
    "authors": [
      "Peng Xu",
      "Haoran Wang",
      "Chuang Wang",
      "Xu Liu"
    ],
    "summary": "As AI Agents based on Large Language Models (LLMs) have shown potential in\npractical applications across various fields, how to quickly deploy an AI agent\nand how to conveniently expand the application scenario of AI agents has become\na challenge. Previous studies mainly focused on implementing all the reasoning\ncapabilities of AI agents within a single LLM, which often makes the model more\ncomplex and also reduces the extensibility of AI agent functionality. In this\npaper, we propose CACA Agent (Capability Collaboration based AI Agent), using\nan open architecture inspired by service computing. CACA Agent integrates a set\nof collaborative capabilities to implement AI Agents, not only reducing the\ndependence on a single LLM, but also enhancing the extensibility of both the\nplanning abilities and the tools available to AI agents. Utilizing the proposed\nsystem, we present a demo to illustrate the operation and the application\nscenario extension of CACA Agent.",
    "pdf_url": "http://arxiv.org/pdf/2403.15137v1",
    "published": "2024-03-22"
  },
  "2502.08864v1": {
    "title": "Off-Switching Not Guaranteed",
    "authors": [
      "Sven Neth"
    ],
    "summary": "Hadfield-Menell et al. (2017) propose the Off-Switch Game, a model of\nHuman-AI cooperation in which AI agents always defer to humans because they are\nuncertain about our preferences. I explain two reasons why AI agents might not\ndefer. First, AI agents might not value learning. Second, even if AI agents\nvalue learning, they might not be certain to learn our actual preferences.",
    "pdf_url": "http://arxiv.org/pdf/2502.08864v1",
    "published": "2025-02-13"
  },
  "2406.00477v1": {
    "title": "Generative AI as Economic Agents",
    "authors": [
      "Nicole Immorlica",
      "Brendan Lucier",
      "Aleksandrs Slivkins"
    ],
    "summary": "Traditionally, AI has been modeled within economics as a technology that\nimpacts payoffs by reducing costs or refining information for human agents. Our\nposition is that, in light of recent advances in generative AI, it is\nincreasingly useful to model AI itself as an economic agent. In our framework,\neach user is augmented with an AI agent and can consult the AI prior to taking\nactions in a game. The AI agent and the user have potentially different\ninformation and preferences over the communication, which can result in\nequilibria that are qualitatively different than in settings without AI.",
    "pdf_url": "http://arxiv.org/pdf/2406.00477v1",
    "published": "2024-06-01"
  }
}